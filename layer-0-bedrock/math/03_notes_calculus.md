0.3 Calculus (for optimization) Notes

Numerical derivative (finite differences):
- Approximate slope using nearby points (central difference is stable).

Gradient descent:
- Move parameters in the negative gradient direction to reduce loss.
- Small step size (learning rate) prevents overshooting.
